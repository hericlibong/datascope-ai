#!/usr/bin/env python3
"""
Test de la g√©n√©ration d'angles √©ditoriaux avec logs d√©taill√©s
Teste la capacit√© de l'IA √† g√©n√©rer des angles journalistiques pertinents
"""

import sys
import os
from pathlib import Path

# Ajouter le r√©pertoire parent au PYTHONPATH pour les imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from playground_debug_mode.logger import debug_logger, timer_decorator
from ai_engine.chains import angles
from ai_engine.utils import token_len
import ai_engine


@timer_decorator(debug_logger)
def test_angles_generation(sample_file: str):
    """Teste la g√©n√©ration d'angles sur un √©chantillon d'article"""
    debug_logger.separator(f"Test g√©n√©ration d'angles - {sample_file}")
    
    # Charger l'√©chantillon
    sample_path = Path(__file__).parent / "samples" / sample_file
    if not sample_path.exists():
        debug_logger.error(f"Fichier √©chantillon non trouv√©", file=str(sample_path))
        return None
    
    with open(sample_path, 'r', encoding='utf-8') as f:
        article_text = f.read()
    
    debug_logger.info(f"Article charg√©", 
                     length=len(article_text), 
                     tokens=token_len(article_text, model=ai_engine.OPENAI_MODEL))
    
    try:
        # Ex√©cuter la g√©n√©ration d'angles
        debug_logger.info("Lancement de la g√©n√©ration d'angles...")
        result = angles.run(article_text)
        
        # Analyser les r√©sultats
        debug_logger.success("G√©n√©ration d'angles termin√©e avec succ√®s")
        debug_logger.metrics("R√©sultats angles",
                           angles_count=len(result.angles),
                           total_characters=sum(len(angle.title) + len(angle.rationale) for angle in result.angles))
        
        # D√©tails des angles g√©n√©r√©s
        for i, angle in enumerate(result.angles):
            debug_logger.info(f"Angle {i+1}",
                            title=angle.title,
                            rationale_length=len(angle.rationale))
            
            # Afficher le rationale tronqu√© pour le debug
            rationale_preview = angle.rationale[:100] + "..." if len(angle.rationale) > 100 else angle.rationale
            debug_logger.debug(f"Rationale {i+1}", content=rationale_preview)
        
        # √âvaluation qualitative des angles
        debug_logger.separator("√âvaluation qualitative", "-", 50)
        
        # V√©rifier la diversit√© des angles
        titles = [angle.title.lower() for angle in result.angles]
        unique_words = set()
        for title in titles:
            unique_words.update(title.split())
        
        diversity_score = len(unique_words) / max(len(titles), 1)
        debug_logger.metrics("Diversit√© des angles", 
                           unique_words_count=len(unique_words),
                           diversity_score=f"{diversity_score:.2f}")
        
        # V√©rifier la pertinence (longueur des rationales)
        avg_rationale_length = sum(len(angle.rationale) for angle in result.angles) / len(result.angles)
        debug_logger.metrics("Qualit√© des rationales",
                           avg_length=f"{avg_rationale_length:.1f}",
                           min_length=min(len(angle.rationale) for angle in result.angles),
                           max_length=max(len(angle.rationale) for angle in result.angles))
        
        # Sauvegarder les r√©sultats
        output_data = {
            "sample_file": sample_file,
            "article_length": len(article_text),
            "token_count": token_len(article_text, model=ai_engine.OPENAI_MODEL),
            "angles_result": {
                "angles_count": len(result.angles),
                "angles": [
                    {
                        "title": angle.title,
                        "rationale": angle.rationale,
                        "title_length": len(angle.title),
                        "rationale_length": len(angle.rationale)
                    }
                    for angle in result.angles
                ]
            },
            "quality_metrics": {
                "diversity_score": diversity_score,
                "avg_rationale_length": avg_rationale_length,
                "unique_words_count": len(unique_words)
            }
        }
        
        debug_logger.save_json(output_data, f"angles_result_{sample_file.split('.')[0]}")
        
        return result
        
    except Exception as e:
        debug_logger.error("Erreur lors de la g√©n√©ration d'angles", error=e)
        return None


@timer_decorator(debug_logger)
def test_angles_consistency():
    """Teste la coh√©rence de la g√©n√©ration d'angles"""
    debug_logger.separator("Test de coh√©rence")
    
    # Article de test simple
    test_article = """
    Le gouvernement fran√ßais annonce un nouveau plan de relance √©conomique de 100 milliards d'euros.
    Ce plan, pr√©sent√© par le Premier ministre √† l'Assembl√©e nationale, vise √† soutenir les entreprises
    et √† cr√©er des emplois dans les secteurs verts et num√©riques.
    """
    
    debug_logger.info("Test de coh√©rence sur 3 g√©n√©rations successives")
    
    results = []
    for i in range(3):
        debug_logger.info(f"G√©n√©ration {i+1}/3")
        try:
            result = angles.run(test_article)
            results.append(result)
            debug_logger.success(f"G√©n√©ration {i+1} r√©ussie", angles_count=len(result.angles))
        except Exception as e:
            debug_logger.error(f"G√©n√©ration {i+1} √©chou√©e", error=e)
            results.append(None)
    
    # Analyser la coh√©rence
    if all(r is not None for r in results):
        debug_logger.info("Analyse de coh√©rence...")
        
        # Comparer le nombre d'angles
        angles_counts = [len(r.angles) for r in results]
        debug_logger.metrics("Coh√©rence - Nombre d'angles",
                           counts=angles_counts,
                           consistent=len(set(angles_counts)) == 1)
        
        # Analyser la similarit√© des titres
        all_titles = []
        for result in results:
            all_titles.extend([angle.title.lower() for angle in result.angles])
        
        unique_titles = set(all_titles)
        similarity_ratio = len(unique_titles) / len(all_titles) if all_titles else 0
        
        debug_logger.metrics("Coh√©rence - Similarit√© des titres",
                           total_titles=len(all_titles),
                           unique_titles=len(unique_titles),
                           similarity_ratio=f"{similarity_ratio:.2f}")
    else:
        debug_logger.warning("Impossible d'analyser la coh√©rence √† cause d'√©checs")


def main():
    """Fonction principale - ex√©cute tous les tests d'angles"""
    debug_logger.separator("üéØ Tests g√©n√©ration d'angles - Playground Debug Mode", "=", 100)
    debug_logger.info("D√©marrage des tests de g√©n√©ration d'angles")
    debug_logger.metrics("Configuration", 
                        model=ai_engine.OPENAI_MODEL,
                        max_tokens=8000)
    
    # Test avec √©chantillons fran√ßais et anglais
    sample_files = ["sample_fr.txt", "sample_en.txt"]
    
    for sample_file in sample_files:
        result = test_angles_generation(sample_file)
        if result:
            debug_logger.success(f"Test {sample_file} r√©ussi")
        else:
            debug_logger.error(f"Test {sample_file} √©chou√©")
    
    # Test de coh√©rence
    test_angles_consistency()
    
    debug_logger.separator("Tests g√©n√©ration d'angles termin√©s", "=", 100)
    debug_logger.success("Tous les tests d'angles sont termin√©s. Consultez les fichiers de sortie pour plus de d√©tails.")


if __name__ == "__main__":
    main()